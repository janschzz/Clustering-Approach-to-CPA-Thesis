{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606160b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Set, Tuple, List\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab97624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframes_from_folder(folder_path: str, file_limit: int) -> List[Tuple[pd.DataFrame, str]]:\n",
    "    \"\"\"\n",
    "    Read dataframes from CSV files in the given folder.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing CSV files.\n",
    "        file_limit (int): Maximum number of files to be read.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[pd.DataFrame, str]]: A list of tuples containing the dataframes and their corresponding filenames.\n",
    "    \"\"\"\n",
    "    tuple_dataframes = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            if len(tuple_dataframes) < file_limit:\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(file_path)\n",
    "                tuple_dataframes.append((df, os.path.basename(file_path)))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return tuple_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bccdf049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframes(tuple_dataframes: List[Tuple[pd.DataFrame, str]]) -> None:\n",
    "    \"\"\"\n",
    "    Clean the dataframes by renaming columns, dropping the 'Unnamed: 0' column, and dropping empty columns.\n",
    "\n",
    "    Args:\n",
    "        tuple_dataframes (List[Tuple[pd.DataFrame, str]]): List of tuples containing the dataframes and their corresponding filenames.\n",
    "    \"\"\"\n",
    "    \n",
    "    # inner function\n",
    "    def drop_empty_columns_in_dataframes(dataframes: List[Tuple[pd.DataFrame, str]]) -> None:\n",
    "        for df, _ in dataframes:\n",
    "            empty_columns = df.columns[df.isnull().all()].tolist()  # get the list of empty columns\n",
    "            df.drop(empty_columns, axis=1, inplace=True)  # drop the empty columns\n",
    "    \n",
    "    # renaming columns, deleting 'Unnamed: 0', and removing empty dataframes\n",
    "    indices_to_delete = []\n",
    "    for index, (df, _) in enumerate(tuple_dataframes):\n",
    "        df.rename(columns=lambda x: x.replace('col', ''), inplace=True)\n",
    "        \n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df.drop('Unnamed: 0', axis=1, inplace=True)  # delete the \"Unnamed: 0\" column\n",
    "        \n",
    "        if df.empty:\n",
    "            indices_to_delete.append(index)  # mark dataframe for deletion if empty\n",
    "    \n",
    "    # reverse sort the indices and delete the empty dataframes\n",
    "    for index in sorted(indices_to_delete, reverse=True):\n",
    "        del tuple_dataframes[index]\n",
    "\n",
    "    # call inner funtion\n",
    "    drop_empty_columns_in_dataframes(tuple_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce4f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_without_label(dataframes: List[Tuple[pd.DataFrame, str]], label_df: pd.DataFrame) -> List[Tuple[pd.DataFrame, str]]:\n",
    "    \"\"\"\n",
    "    Drop columns for which no gold standard exists.\n",
    "\n",
    "    Args:\n",
    "        dataframes (List[Tuple[pd.DataFrame, str]]): List of tuples containing the dataframes and their corresponding filenames.\n",
    "        label_df (pd.DataFrame): DataFrame containing the gold standard annotations.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[pd.DataFrame, str]]: List of tuples containing the cleaned dataframes and their corresponding filenames.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy\n",
    "    tuple_dataframes_copy = [(df.copy(), name) for df, name in dataframes]\n",
    "\n",
    "    # indices of dataframes to delete\n",
    "    to_delete = []\n",
    "\n",
    "    # iterate over dataframes\n",
    "    for table_index, (df, filename) in enumerate(tuple_dataframes_copy):\n",
    "        for column_index, col in enumerate(df.columns):\n",
    "            if not any((label_df['table_id'] == filename[:-4] + \"_dbpedia\") & (label_df['target_column'] == column_index)):\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "        if df.empty:\n",
    "            to_delete.append(table_index)\n",
    "        else:\n",
    "            tuple_dataframes_copy[table_index] = (df, filename)\n",
    "\n",
    "    # delete empty dataframes from the list in reverse order to prevent index shifting\n",
    "    for index in reversed(to_delete):\n",
    "        del tuple_dataframes_copy[index]\n",
    "\n",
    "    return tuple_dataframes_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d22a28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_columns(tuple_dataframes: List[Tuple[pd.DataFrame, str]], n: int) -> List[Tuple[pd.DataFrame, str]]:\n",
    "    \"\"\"\n",
    "    Sample 'n' columns from all DataFrames combined, delete non-sampled columns, and filter out empty DataFrames.\n",
    "\n",
    "    Args:\n",
    "        tuple_dataframes (List[Tuple[pd.DataFrame, str]]): A list of tuples containing the dataframes and their corresponding filenames.\n",
    "        n (int): Number of columns to sample in total.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[pd.DataFrame, str]]: A list of tuples containing the non-empty dataframes and their corresponding filenames.\n",
    "    \"\"\"\n",
    "    # add prefixes to ensure unique column names in combined DataFrame\n",
    "    all_dfs = []\n",
    "    for idx, (df, _) in enumerate(tuple_dataframes):\n",
    "        df_prefixed = df.add_prefix(f\"df{idx}_\")\n",
    "        all_dfs.append(df_prefixed)\n",
    "\n",
    "    combined_df = pd.concat(all_dfs, axis=1)\n",
    "\n",
    "    # sample 'n' columns from the combined DataFrame\n",
    "    if n >= len(combined_df.columns):\n",
    "        sampled_columns = combined_df.columns\n",
    "    else:\n",
    "        sampled_columns = random.sample(list(combined_df.columns), n)\n",
    "\n",
    "    # filter combined DataFrame to keep only the sampled columns\n",
    "    sampled_combined_df = combined_df[sampled_columns]\n",
    "\n",
    "    filtered_dataframes = []\n",
    "\n",
    "    # split the combined DataFrame back into individual DataFrames and filter out any empty DataFrames\n",
    "    for idx, (_, filename) in enumerate(tuple_dataframes):\n",
    "        relevant_cols = [col for col in sampled_combined_df.columns if col.startswith(f\"df{idx}_\")]\n",
    "        df_sampled = sampled_combined_df[relevant_cols].rename(columns=lambda x: x.split(\"_\", 1)[1])\n",
    "        if not df_sampled.empty:\n",
    "            filtered_dataframes.append((df_sampled, filename))\n",
    "\n",
    "    return filtered_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "250afd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ground_truth_map(label_df: pd.DataFrame, tuple_dataframes: List[Tuple[pd.DataFrame, str]]) -> Dict[str, Set[int]]:\n",
    "    \"\"\"\n",
    "    Create a ground truth map for evaluation.\n",
    "\n",
    "    Args:\n",
    "        label_df (pd.DataFrame): DataFrame containing true labels for evaluation.\n",
    "        tuple_dataframes (List[Tuple[pd.DataFrame, str]]): List of tuples containing the dataframes and their corresponding filenames.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Set[int]]: A dictionary mapping label names to sets of global indices that belong to each label.\n",
    "    \"\"\"\n",
    "    ground_truth = defaultdict(set)\n",
    "\n",
    "    for table_index, (df, filename) in enumerate(tuple_dataframes):\n",
    "        for new_col_index, old_col_index in enumerate(df.columns):\n",
    "            label = label_df.query(f\"table_id == '{filename[:-4] + '_dbpedia'}' and target_column == {old_col_index}\")['annotation_label']\n",
    "\n",
    "            if label.empty:\n",
    "                continue\n",
    "\n",
    "            global_index = sum(df.shape[1] for df, _ in tuple_dataframes[:table_index]) + new_col_index\n",
    "            ground_truth[label.iloc[0]].add(global_index)\n",
    "\n",
    "            if len(label.values) != 1:\n",
    "                raise ValueError(\"Unexpected number of label values\")\n",
    "\n",
    "    for tuple_dataframe in tuple_dataframes:\n",
    "        tuple_dataframe[0].columns = range(len(tuple_dataframe[0].columns))\n",
    "\n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94d41b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_column_similarity_sbert(dataframe_list, sample_size=12):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between columns of dataframes using Sentence BERT embeddings.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe_list (List[pd.DataFrame]): A list of dataframes to be processed.\n",
    "        sample_size (int, default=100): Number of entries to be used from each column for embeddings.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing cosine distances between every pair of columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Create a dict to store the embeddings for each column\n",
    "    column_embeddings = {}\n",
    "\n",
    "    # Loop over the dataframes and columns\n",
    "    count = 0\n",
    "    for df in dataframe_list:\n",
    "        for col in df.columns:\n",
    "            # Sample a subset of entries from the column\n",
    "            samples = df[col].dropna().astype(str)\n",
    "            samples = samples.sample(min(len(samples), sample_size))\n",
    "            \n",
    "            sample_embeddings = model.encode(samples.tolist())\n",
    "            column_embeddings[count] = np.mean(sample_embeddings, axis=0)\n",
    "            count += 1\n",
    "\n",
    "    # Prepare the embedding matrix\n",
    "    embedding_matrix = np.vstack(list(column_embeddings.values()))\n",
    "\n",
    "    # Calculate cosine distance\n",
    "    distance = 1 - cosine_similarity(embedding_matrix)\n",
    "\n",
    "    # Convert the distance matrix to a dataframe\n",
    "    distance_df = pd.DataFrame(distance, index=column_embeddings.keys(), columns=column_embeddings.keys())\n",
    "\n",
    "    return distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a3a80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering(distance_matrix: np.ndarray, n_clusters: int) -> Dict[int, Set[int]]:\n",
    "    \"\"\"\n",
    "    Perform hierarchical clustering on the distance matrix.\n",
    "\n",
    "    Args:\n",
    "        distance_matrix (np.ndarray): Pairwise distance matrix.\n",
    "        n_clusters (int): Number of clusters to create.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int, Set[int]]: A dictionary mapping cluster labels to sets of indices that belong to each cluster.\n",
    "    \"\"\"\n",
    "    # create an AgglomerativeClustering model\n",
    "    model = AgglomerativeClustering(n_clusters=n_clusters, metric='precomputed', linkage='average')\n",
    "\n",
    "    # fit the model to the distance matrix\n",
    "    model.fit(distance_matrix)\n",
    "\n",
    "    # get the cluster labels\n",
    "    labels = model.labels_\n",
    "\n",
    "    # create a dictionary that maps each cluster label to the set of indices that belong to that cluster\n",
    "    clusters = defaultdict(set)\n",
    "    for idx, label in enumerate(labels):\n",
    "        clusters[label].add(idx)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd635296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_micro(truth_dict: Dict[str, Set[int]], result_dict: Dict[int, Set[int]]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate clustering performance using micro-average precision, recall.\n",
    "\n",
    "    Args:\n",
    "        truth_dict (Dict[str, Set[int]]): Ground truth mapping label names to sets of global indices.\n",
    "        result_dict (Dict[int, Set[int]]): Resulting clustering mapping cluster labels to sets of indices.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: Micro-average precision and recall\n",
    "    \"\"\"\n",
    "    # creating the contingency matrix\n",
    "    contingency_matrix = np.zeros((len(truth_dict), len(result_dict)))\n",
    "\n",
    "    truth_labels = list(truth_dict.keys())\n",
    "    result_labels = list(result_dict.keys())\n",
    "\n",
    "    for i, truth_label in enumerate(truth_labels):\n",
    "        for j, result_label in enumerate(result_labels):\n",
    "            # length of intersection between clusters\n",
    "            # contingency_matrix[i, j] is the number of (global) indices assigned to both clusters\n",
    "            contingency_matrix[i, j] = len(truth_dict[truth_label] & result_dict[result_label])\n",
    "\n",
    "    # calculate precision, recall, and f1-score for each label and average them\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1_score = 0\n",
    "    total_weight = 0\n",
    "\n",
    "    for i, _ in enumerate(result_labels):\n",
    "        tp = np.max(contingency_matrix[:, i])  # maximum element in column i (True Positives)\n",
    "        best_match_index = np.argmax(contingency_matrix[:, i])  # get the index of the best match (TP - index)\n",
    "        tp_plus_fp = np.sum(contingency_matrix[best_match_index, :])  # sum of elements in row of best match (TP + FP)\n",
    "        tp_plus_fn = np.sum(contingency_matrix[:, i])  # sum of elements in column i (TP + FN)\n",
    "\n",
    "        weight = tp_plus_fn  # the weight for each label is the total number of true positives plus false negatives\n",
    "\n",
    "        if tp_plus_fp > 0:\n",
    "            precision = tp / tp_plus_fp\n",
    "            total_precision += weight * precision\n",
    "        if tp_plus_fn > 0:\n",
    "            recall = tp / tp_plus_fn\n",
    "            total_recall += weight * recall\n",
    "\n",
    "        total_weight += weight\n",
    "\n",
    "    avg_precision = total_precision / total_weight\n",
    "    avg_recall = total_recall / total_weight\n",
    "\n",
    "    return avg_precision, avg_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4695f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_script() -> dict:\n",
    "    metrics = {}\n",
    "    \n",
    "    # path to the folder containing CSV files \n",
    "    base_dir = os.path.dirname(os.path.abspath(\"Baseline.ipynb\"))\n",
    "    folder_path = os.path.join(base_dir, \"..\",\"Data\", \"GitTables\", \"tables\")\n",
    "    \n",
    "    # maximum number of files to be read\n",
    "    file_limit = 1500\n",
    "    \n",
    "    # read dataframes from the folder\n",
    "    tuple_dataframes = read_dataframes_from_folder(folder_path, file_limit)\n",
    "    \n",
    "    # reading in true labels for evaluation\n",
    "    base_dir = os.path.dirname(os.path.abspath(\"Baseline.ipynb\"))\n",
    "    label_path = os.path.join(base_dir, \"..\", \"Data\", \"GitTables\", \"dbpedia_gt.csv\")\n",
    "    label_df = pd.read_csv(label_path)\n",
    "\n",
    "    \n",
    "    clean_dataframes(tuple_dataframes)\n",
    "    \n",
    "    # Clean the dataset and drop columns without gold standard annotations\n",
    "    tuple_dataframes_copy = drop_columns_without_label(tuple_dataframes, label_df)\n",
    "    \n",
    "    n = 2000\n",
    "    random_sample = sample_columns(tuple_dataframes_copy, 2000)\n",
    "    \n",
    "    ground_truth_map = create_ground_truth_map(label_df, random_sample)\n",
    "    \n",
    "    # extract dataframes from the tuple list\n",
    "    dataframes = [df for df, _ in random_sample]\n",
    "    \n",
    "    # calculate column similarity using Sentence-BERT embeddings\n",
    "    s = 12\n",
    "    d = calculate_column_similarity_sbert(dataframes, sample_size=s)\n",
    "    \n",
    "    # clustering hierarchically\n",
    "    num_hierarchical_clusters = len(ground_truth_map.keys())\n",
    "\n",
    "    cl = hierarchical_clustering(d, num_hierarchical_clusters)\n",
    "\n",
    "    # evaluate clustering performance\n",
    "    precision, recall = evaluate_micro(ground_truth_map, cl)\n",
    "    metrics['precision'] = precision\n",
    "    metrics['recall'] = recall\n",
    "    metrics['f1_score'] = 2*(precision*recall)/(precision + recall)\n",
    "    metrics['calculated_embeddings'] = (0.5 * n*(n-1))*s\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59453eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee4d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9ce9079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5123353912265673, 'recall': 0.5959982283246595, 'f1_score': 0.5508969850551932, 'calculated_embeddings': 23988000.0}\n"
     ]
    }
   ],
   "source": [
    "# EXECUTE HERE\n",
    "\n",
    "# ADJUST ACCORDING TO PREFERENCE\n",
    "# FOR STABLE RESULT CONISDER num_iteraitons = 10,\n",
    "# FOR QUICK EXECUTION num_itertaions = 1\n",
    "num_iterations = 2\n",
    "\n",
    "results = [execute_script() for _ in range(num_iterations)]\n",
    "averages = {key: sum([result[key] for result in results]) / num_iterations for key in results[0]}\n",
    "print(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b079a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50bfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc33e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS AS USED IN THESIS, DO NOT EXECUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53632a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial_columns': 18578.0, 'algorithm_runtime': 37.654068326950075, 'precision': 0.5248148482539488, 'recall': 0.5840061962309203, 'f1_score': 0.551536919780547, 'calculated_embeddings': 19990000.0}\n"
     ]
    }
   ],
   "source": [
    "results = [execute_script() for _ in range(10)]\n",
    "averages = {key: sum([result[key] for result in results]) / 10 for key in results[0]}\n",
    "print(averages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
